{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c9354",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from llm_client import HelloAgentsLLM\n",
    "import ast\n",
    "\n",
    "PLANNER_PROMPT_TEMPLATE = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„AIè§„åˆ’ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æå‡ºçš„å¤æ‚é—®é¢˜åˆ†è§£æˆä¸€ä¸ªç”±å¤šä¸ªç®€å•æ­¥éª¤ç»„æˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\n",
    "è¯·ç¡®ä¿è®¡åˆ’ä¸­çš„æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„ã€å¯æ‰§è¡Œçš„å­ä»»åŠ¡ï¼Œå¹¶ä¸”ä¸¥æ ¼æŒ‰ç…§é€»è¾‘é¡ºåºæ’åˆ—ã€‚\n",
    "ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªPythonåˆ—è¡¨ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªæè¿°å­ä»»åŠ¡çš„å­—ç¬¦ä¸²ã€‚\n",
    "é—®é¢˜: {question}\n",
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºä½ çš„è®¡åˆ’,```pythonä¸```ä½œä¸ºå‰åç¼€æ˜¯å¿…è¦çš„:\n",
    "```python\n",
    "[\"æ­¥éª¤1\", \"æ­¥éª¤2\", \"æ­¥éª¤3\", ...]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# å‡å®š llm_client.py ä¸­çš„ HelloAgentsLLM ç±»å·²ç»å®šä¹‰å¥½\n",
    "# from llm_client import HelloAgentsLLM\n",
    "\n",
    "class Planner:\n",
    "    def __init__(self, llm_client):\n",
    "        self.llm_client = llm_client\n",
    "\n",
    "    def plan(self, question: str) -> list[str]:\n",
    "        prompt = PLANNER_PROMPT_TEMPLATE.format(question=question)\n",
    "        \n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "        print(\"--- æ­£åœ¨ç”Ÿäº§è®¡åˆ’ ---\")\n",
    "        response_text = self.llm_client.think(messages=messages) or \"\"\n",
    "        print(f\"âœ… è®¡åˆ’å·²ç”Ÿæˆ:\\n{response_text}\")\n",
    "\n",
    "        try:\n",
    "            plan_str = response_text.split(\"```python\")[1].split(\"```\")[0].strip()\n",
    "            plan = ast.literal_eval(plan_str)\n",
    "            return plan if isinstance(plan, list) else []\n",
    "        except (ValueError, SyntaxError, IndexError) as e:\n",
    "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‡ºé”™: {e}\")\n",
    "            print(f\"åŸå§‹å“åº”: {response_text}\")\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è§£æè®¡åˆ’æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "EXECUTOR_PROMPT_TEMPLATE = \"\"\"\n",
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„AIæ‰§è¡Œä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸¥æ ¼æŒ‰ç…§ç»™å®šçš„è®¡åˆ’ï¼Œä¸€æ­¥æ­¥åœ°è§£å†³é—®é¢˜ã€‚\n",
    "ä½ å°†æ”¶åˆ°åŸå§‹é—®é¢˜ã€å®Œæ•´çš„è®¡åˆ’ã€ä»¥åŠåˆ°ç›®å‰ä¸ºæ­¢å·²ç»å®Œæˆçš„æ­¥éª¤å’Œç»“æœã€‚\n",
    "è¯·ä½ ä¸“æ³¨äºè§£å†³â€œå½“å‰æ­¥éª¤â€ï¼Œå¹¶ä»…è¾“å‡ºè¯¥æ­¥éª¤çš„æœ€ç»ˆç­”æ¡ˆï¼Œä¸è¦è¾“å‡ºä»»ä½•é¢å¤–çš„è§£é‡Šæˆ–å¯¹è¯ã€‚\n",
    "\n",
    "# åŸå§‹é—®é¢˜:\n",
    "{question}\n",
    "\n",
    "# å®Œæ•´è®¡åˆ’:\n",
    "{plan}\n",
    "\n",
    "# å†å²æ­¥éª¤ä¸ç»“æœ:\n",
    "{history}\n",
    "\n",
    "# å½“å‰æ­¥éª¤:\n",
    "{current_step}\n",
    "\n",
    "è¯·ä»…è¾“å‡ºé’ˆå¯¹â€œå½“å‰æ­¥éª¤â€çš„å›ç­”:\n",
    "\"\"\"\n",
    "\n",
    "class Executor:\n",
    "    def __init__(self,llm_client):\n",
    "        self.llm_client = llm_client\n",
    "\n",
    "    def execute(self, question: str, plan: list[str]) -> str:\n",
    "        history = \"\"\n",
    "\n",
    "        print(\"\\n --- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\")\n",
    "        \n",
    "        for i, step in enumerate(plan):\n",
    "            prompt = EXECUTOR_PROMPT_TEMPLATE.format(\n",
    "                question=question,\n",
    "                plan=plan,\n",
    "                history = history if history else \"æ— \",\n",
    "                current_step = step\n",
    "            )\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "            response_text = self.llm_client.think(messages=messages) or \"\"\n",
    "\n",
    "            history += f\"æ­¥éª¤ {i+1}: {step}\\nç»“æœ: {response_text}\\n\\n]\"\n",
    "\n",
    "            print(f\"âœ… æ­¥éª¤ {i+1} å·²å®Œæˆï¼Œç»“æœ: {response_text}\")\n",
    "\n",
    "        # å¾ªç¯ç»“æŸåï¼Œæœ€åä¸€æ­¥çš„å“åº”å°±æ˜¯æœ€ç»ˆç­”æ¡ˆ\n",
    "        final_answer = response_text\n",
    "        return final_answer\n",
    "\n",
    "\n",
    "class PlanAndSolveAgent:\n",
    "    def __init__(self, llm_client):\n",
    "        self.llm_client = llm_client\n",
    "        self.planner = Planner(self.llm_client)\n",
    "        self.executor = Executor(self.llm_client)\n",
    "\n",
    "    def run(self, question: str):\n",
    "        print(f\"\\n--- å¼€å§‹å¤„ç†é—®é¢˜ ---\\né—®é¢˜: {question}\")\n",
    "\n",
    "        plan = self.planner.plan(question=question)\n",
    "\n",
    "        if not plan:\n",
    "            print(\"\\n--- ä»»åŠ¡ç»ˆæ­¢ --- \\næ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¡ŒåŠ¨è®¡åˆ’ã€‚\")\n",
    "            return\n",
    "        \n",
    "        final_answer = self.executor.execute(question, plan)\n",
    "\n",
    "        print(f\"\\n--- ä»»åŠ¡å®Œæˆ ---\\næœ€ç»ˆç­”æ¡ˆ: {final_answer}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        llm_client = HelloAgentsLLM()\n",
    "        agent = PlanAndSolveAgent(llm_client)\n",
    "        question = \"ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\"\n",
    "        agent.run(question=question)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ea839",
   "metadata": {},
   "source": [
    "    \n",
    "--- å¼€å§‹å¤„ç†é—®é¢˜ ---\n",
    "é—®é¢˜: ä¸€ä¸ªæ°´æœåº—å‘¨ä¸€å–å‡ºäº†15ä¸ªè‹¹æœã€‚å‘¨äºŒå–å‡ºçš„è‹¹æœæ•°é‡æ˜¯å‘¨ä¸€çš„ä¸¤å€ã€‚å‘¨ä¸‰å–å‡ºçš„æ•°é‡æ¯”å‘¨äºŒå°‘äº†5ä¸ªã€‚è¯·é—®è¿™ä¸‰å¤©æ€»å…±å–å‡ºäº†å¤šå°‘ä¸ªè‹¹æœï¼Ÿ\n",
    "--- æ­£åœ¨ç”Ÿäº§è®¡åˆ’ ---\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "```python\n",
    "[\"å°†å‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡è®¾ä¸º 15ï¼Œè®°ä¸º M = 15ã€‚\",\"è®¡ç®—å‘¨äºŒçš„è‹¹æœæ•°é‡ï¼ŒT = 2 * Mã€‚\",\"è®¡ç®—å‘¨ä¸‰çš„è‹¹æœæ•°é‡ï¼ŒW = T - 5ã€‚\",\"è®¡ç®—ä¸‰å¤©çš„æ€»é”€é‡ S = M + T + Wã€‚\",\"è¾“å‡ºæ€»é”€é‡ Sï¼Œå³ä¸‰å¤©æ€»å…±å–å‡ºçš„è‹¹æœæ•°é‡ã€‚\"]\n",
    "```\n",
    "âœ… è®¡åˆ’å·²ç”Ÿæˆ:\n",
    "```python\n",
    "[\"å°†å‘¨ä¸€å–å‡ºçš„è‹¹æœæ•°é‡è®¾ä¸º 15ï¼Œè®°ä¸º M = 15ã€‚\",\"è®¡ç®—å‘¨äºŒçš„è‹¹æœæ•°é‡ï¼ŒT = 2 * Mã€‚\",\"è®¡ç®—å‘¨ä¸‰çš„è‹¹æœæ•°é‡ï¼ŒW = T - 5ã€‚\",\"è®¡ç®—ä¸‰å¤©çš„æ€»é”€é‡ S = M + T + Wã€‚\",\"è¾“å‡ºæ€»é”€é‡ Sï¼Œå³ä¸‰å¤©æ€»å…±å–å‡ºçš„è‹¹æœæ•°é‡ã€‚\"]\n",
    "```\n",
    "\n",
    " --- æ­£åœ¨æ‰§è¡Œè®¡åˆ’ ---\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "M = 15\n",
    "âœ… æ­¥éª¤ 1 å·²å®Œæˆï¼Œç»“æœ: M = 15\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "30\n",
    "âœ… æ­¥éª¤ 2 å·²å®Œæˆï¼Œç»“æœ: 30\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "25\n",
    "âœ… æ­¥éª¤ 3 å·²å®Œæˆï¼Œç»“æœ: 25\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "70\n",
    "âœ… æ­¥éª¤ 4 å·²å®Œæˆï¼Œç»“æœ: 70\n",
    "ğŸ§  æ­£åœ¨è°ƒç”¨ gpt-5-nano æ¨¡å‹...\n",
    "âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:\n",
    "70\n",
    "âœ… æ­¥éª¤ 5 å·²å®Œæˆï¼Œç»“æœ: 70\n",
    "\n",
    "--- ä»»åŠ¡å®Œæˆ ---\n",
    "æœ€ç»ˆç­”æ¡ˆ: 70"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
